# 8일차

### 1. 상관관계분석

# 키와 몸무게
height<-c(164,175,166,185)
weight<-c(62,70,64,86)

# 상관관계 구하기
round(cor(height,weight),3)

# 건강정보 데이터
library(moonBook)
data(acs)
str(acs)

acs2<-acs[,c(1,6:9)]
cor(acs2)  # NA값때문에 상관관계 계산되지 않음
cor(acs2,use="na.or.complete")  # NA값 존재시 NA 제외후 계산

# 산점도행렬 (별 개수는 유의확률을 나타내줌. 별보다는 숫자를 중심으로 보면됨)
# 방법1
library(psych)
pairs.panels(acs2)

# 방법2
library(PerformanceAnalytics)
chart.Correlation(acs2, histogram=TRUE, pch=19)

# outlier가 상관계수에 미치는 영향
dat<-data.frame(
  a=c(15,20,25,27,31,25,23,23,42,12,34,23,40),
  b=c(50,55,52,52,56,54,62,56,70,46,43,50,54)
)
plot(dat$a,dat$b)
abline(lm(dat$b~dat$a))
cor(dat$a,dat$b)

# outlier 추가시 그래프가 왜곡되고 상관계수도 커짐
# 상관계수는 outlier에 민감하므로 처리 필요!
dat[14,]<-c(200,230)
plot(dat$a,dat$b)
abline(lm(dat$b~dat$a))
cor(dat$a,dat$b)

# 히트맵으로 상관계수 확인하기
library(corrplot)

# na값이 있으면 분산을 못 구하므로 na.or.complete 꼭 필요
corrplot(cor(acs2,use="na.or.complete"))
corrplot(cor(acs2,use="na.or.complete"),method="square")
corrplot(cor(acs2,use="na.or.complete"),method="ellipse")
corrplot(cor(acs2,use="na.or.complete"),method="number")
corrplot(cor(acs2,use="na.or.complete"),method="shade")
corrplot(cor(acs2,use="na.or.complete"),method="color")
corrplot(cor(acs2,use="na.or.complete"),method="pie")

# cor의 비모수적 표현들 (pearson이 기본형)
# spearman - 순위가 있는 변수 간의 피어슨 상관계수. 값 단위가 다를때 랭킹 기준으로 상관관계 체크
# kendall - 순위 일치하는 경우, 일치하지 않는 경우 비교하여 계산
cor(acs$height,acs$weight, use="na.or.complete")
cor(acs$height,acs$weight, method="spearman", use="na.or.complete")
cor(height,weight,method="kendall")


# 연습문제
data(iris)
head(iris)

# 1. iris 데이터셋에서 Sepal.Length와 가장 상관있는 변수 찾기
cor(iris$Sepal.Length, iris$Sepal.Width)
cor(iris$Sepal.Length, iris$Petal.Length)  #가장 상관관계 큼
cor(iris$Sepal.Length, iris$Petal.Width)

plot(iris$Sepal.Length,iris$Petal.Length)
pairs.panels(iris[,1:4])

# 2. mpg 데이터셋에서 변수간 상관관계 확인해보기
data(mtcars)
head(mtcars)

pairs.panels(mtcars[,1:7])
chart.Correlation(mtcars[,1:7], histogram=TRUE, pch=19)


### 2. t검정 (집단에 대한 평균 비교)
# ex. 5시대 구매금액, 6시대 구매금액. 두 그룹간 구매액 평균 차이가 있는지 확인하고 싶을 때
# 독립표본 t검정 : 서로 독립된 두 집단
# 대응표본 t검정 : 같은 집단, 특정 조치하기 전과 후 비교

# 나이, 점수 데이터
t_data<-data.frame(
  group=c(1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2),
  score=c(100,100,80,50,40,90,20,50,50,70,30,40,30,70,30,40,30,60,30,60),
  age=c(80,20,30,70,90,20,30,60,50,50,20,30,20,20,25,10,13,12,11,10))

library(tidyverse)
library(ggplot2)

# 박스플랏으로 그룹별 score, age 분포 확인.
ggplot(t_data,aes(x=factor(group), y=score, fill=factor(group))) + geom_boxplot()
ggplot(t_data,aes(x=factor(group), y=age, fill=factor(group))) + geom_boxplot()


# 1) 독립표본 t검정
# 정규성 검정 :  shapiro.test
# 실무에서는 데이터 30개 이상이면 중심극한정리에 의해
# 정규성 만족한다고 보고 바로 등분산검정 하는 경우 많음
shapiro.test(t_data$score)
# p-value가 0.05보다 크므로 정규성을 가짐(귀무가설 채택)

# 등분산성 검정 : var.test
# group 컬럼 정보에 따라 두 데이터셋으로 나누기
t_data_1<-t_data[t_data$group==1,]
t_data_2<-t_data[t_data$group==2,]

# 등분산인지 p-value 보고 확인
var.test(t_data_1$age,t_data_2$age)
var.test(t_data_1$score,t_data_2$score)
# age는 p-value가 0.05보다 작으므로 등분산 아님
# score은 p-value가 0.05보다 크므로 등분산임

# t검정 : t.test
# var.equal=T가 디폴트
# 등분산 검정 통과하지 못한 경우 var.equal = F로 설정

# score 변수 t검정 (var.equal = T)
t.test(t_data_1$score, t_data_2$score, var.equal=T)
t.test(score~group, data=t_data, var.equal=T)

# age 변수 t검정 (var.equal = F)
t.test(t_data_1$age, t_data_2$age, var.equal=F)
t.test(age~group, data=t_data, var.equal=F)

# score, age 모두 p-value가 0.05보다 작으므로 통계적으로 유의한 차이가 있다고 봄


# 2) 대응표본 t검정 (동일집단 전/후비교)
# 대응표본은 파라미터에 paired=T를 추가 (없으면 독립표본)

# 투약 전후 데이터 : 약의 효과가 있는지 확인하고 싶을 때
before_op = c(137,119,117,122,132,110,114,117)
after_op = c(126,111,117,116,135,110,113,112)
t.test(before_op, after_op, paired=T)
# 귀무가설 채택 : 사전, 사후의 차이는 없다

# 과외 전후 데이터 : 과외 효과가 있는지 확인하고 싶을 때
mid = c(16,20,21,22,23,22,27,25,27,28)
final = c(19,20,24,24,25,25,26,26,28,32)
t.test(mid, final, paired=TRUE)
# 대립가설 채택 : 중간, 기말의 차이가 있다


# 연습문제
# 1. 다음 데이터를 갖고 T검정을 하시오 (정규성 검정 생략)
a = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179)
b = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)

var.test(a,b)  # p-value가 0.05보다 크므로 등분산이다
t.test(a,b)  # p-value가 0.05보다 크므로 a,b 통계적 차이 없다

# 2. am 변수에 따라 mpg 변수에 차이가 있는지 확인하시오
data(mtcars)
head(mtcars)
unique(mtcars['am'])  # am 컬럼에는 0 혹은 1의 값 존재

# 등분산성 검정 : p-value가 0.05보다 크므로 등분산임
var.test(mtcars[mtcars$am==0, 'mpg'], mtcars[mtcars$am==1, 'mpg'])

# t검정 : p-value가 0.05보다 작으므로 am값에 따라 mpg값에 통계적으로 유의한 차이가 있다
t.test(mtcars[mtcars$am==0, 'mpg'], mtcars[mtcars$am==1, 'mpg'], var.equal = T)


# 3) Anova(Analysis of Variance) test (3개 이상 그룹의 평균을 비교하는 분산분석)
# 1~3 그룹별 점수 평균 차이가 있는지 확인하고 싶을 때
anova_data<-data.frame(group=c(1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3),
  score=c(50.5, 52.1, 51.9, 52.4, 50.6, 51.4, 51.2, 52.2, 51.5, 50.8,47.5, 47.7, 46.6, 47.1, 47.2, 47.8, 45.2, 47.4, 45.0, 47.9,46.0, 47.1, 45.6, 47.1, 47.2, 46.4, 45.9, 47.1, 44.9, 46.2))

ggplot(anova_data, aes(x=factor(group), y=score, fill=factor(group))) + geom_boxplot()
tapply(anova_data$score, anova_data$group, mean)  # 평균값
tapply(anova_data$score, anova_data$group, max)   # 최대값

# 등분산성 검정 : bartlett.test
# t-test와는 달리 아래와 같이 표시하는 방법밖에 없음 (주의 : group 데이터 factor로 묶어줘야함)
# p-value가 0.05보다 크므로 귀무가설 기각하지 않음 : 등분산 확인
bartlett.test(score ~ as.factor(group), data=anova_data)

# oneway.test : p-value가 0.05보다 작으므로 귀무가설 기각, 적어도 2개 이상의 그룹간 차이가 있다
# oneway.test와 aov는 역할은 같으나 aov는 어떤 그룹끼리 차이가 있는지까지 보여주고, oneway.test는 가설 검정만 한다는 차이가 있다
oneway.test(score~group,data=anova_data,var.equal = T)

# 그룹간, 그룹내 분산분석 표를 보고싶으면 aov(사후검정에 특화)
# summary에서 Pr(>F) p-value값도 확인 가능 (*** 붙어있으면 유의미)
a1 <- aov(score~group, data=anova_data)
summary(aov(score~group, data=anova_data))

# 사후검정 : 방법은 몇십개가 있으나 차이가 크진 않고, 그룹간 차이가 없으면 굳이 안해도 됨
library(laercio)

# 방법1 : LDuncan
LDuncan(a1, "group")

# 방법2 : TukeyHSD
# group에 해당하는 부분이 문자형 이어야함
# 2그룹-1그룹, 3그룹-1그룹, 3그룹-2그룹 각각에 대한 summary 볼수있음
TukeyHSD(aov(score ~ as.character(group), data=anova_data))
plot(TukeyHSD(aov(score ~ as.character(group), data=anova_data)))

# 등분산이 아닐경우
anova_data2 <- data.frame(group=c(1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3),
  score=c(70, 30, 20.3, 85.3, 50.6, 51.4, 51.2, 52.2, 51.5, 50.8,47.5, 47.7, 46.6, 47.1, 47.2, 47.8, 45.2, 47.4, 45.0, 47.9,46.0, 47.1, 45.6, 47.1, 47.2, 46.4, 45.9, 47.1, 44.9, 46.2))

# 등분산성 검정 : bartlett.test
# p-value가 0.05보다 작으므로 귀무가설 기각 : 등분산 아님
bartlett.test(score~as.factor(group),data=anova_data2)

# oneway.test : var.equal = F로 놓고 진행
# p-value가 0.05보다 크므로 귀무가설 기각 : 적어도 2개 이상의 그룹간 차이가 있다
oneway.test(score~group, data=anova_data2, var.equal = F)

a2 <- aov(score~group, data = anova_data2)
summary(aov(score~group, data = anova_data2))

# 사후검정
# 방법1 : LDuncan
LDuncan(a2, "group")

# 방법2 : TukeyHSD
TukeyHSD(aov(score~as.character(group),data=anova_data2))
plot(TukeyHSD(aov(score~as.character(group),data=anova_data2)))
